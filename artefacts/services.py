# apps/artefacts/services.py
"""
Service orchestrant la logique mÃ©tier des artefacts.

ResponsabilitÃ©s :
- CrÃ©ation et enregistrement des artefacts
- Gestion du cycle de vie (refs, cleanup)
- Coordination entre BDD, FS et cache
"""
import logging
from typing import Dict, Any, Optional, Tuple, BinaryIO
from django.db import transaction
from django.conf import settings

from .models import ArtefactMeta, ArtefactAccessLog
from .storage import artefact_storage

logger = logging.getLogger("notelib")


class ArtefactService:
    """
    Service de gestion des artefacts.
    
    Orchestration de bout en bout :
    - CrÃ©ation : sÃ©rialisation + compression + stockage + mÃ©tadonnÃ©es BDD
    - Lecture : chargement depuis FS + dÃ©sÃ©rialisation
    - Suppression : vÃ©rification refs + cleanup FS + BDD
    """
    
    def __init__(self):
        self.storage = artefact_storage
        self.max_size = getattr(
            settings,
            'NOTELIB_ARTIFACT_MAX_BYTES',
            100 * 1024 * 1024  # 100 MB par dÃ©faut
        )
    
    def create_artefact(
        self,
        obj: object,
        feature_hash: Optional[str] = None,
        meta: Optional[Dict[str, Any]] = None
    ) -> ArtefactMeta:
        """
        CrÃ©e un artefact depuis un objet Python.
        
        Workflow :
        1. SÃ©rialise + compresse + calcule hash
        2. VÃ©rifie si dÃ©jÃ  existant (dÃ©duplication)
        3. Sauvegarde sur FS
        4. CrÃ©e l'entrÃ©e BDD
        
        Args:
            obj: Objet Python Ã  persister
            feature_hash: Hash de la feature productrice (optionnel)
            meta: MÃ©tadonnÃ©es additionnelles
        
        Returns:
            Instance ArtefactMeta crÃ©Ã©e ou existante
        
        Raises:
            ValueError: Si taille > max autorisÃ©e
        """
        # SÃ©rialisation + compression
        relative_path, size_compressed, size_raw, hash_value = self.storage.save(obj)
        
        # VÃ©rification de la taille
        if size_compressed > self.max_size:
            # Nettoyage du fichier crÃ©Ã©
            self.storage.delete(hash_value)
            raise ValueError(
                f"Artefact too large: {size_compressed} bytes "
                f"(max: {self.max_size} bytes)"
            )
        
        # Recherche si artefact dÃ©jÃ  existant (dÃ©duplication)
        try:
            existing = ArtefactMeta.objects.get(hash=hash_value)
            logger.info(f"â„¹ï¸  Artefact deduplicated: {hash_value[:8]}")
            return existing
        except ArtefactMeta.DoesNotExist:
            pass
        
        # RÃ©cupÃ©ration de la feature si fournie
        feature = None
        if feature_hash:
            from features.models import FeatureMeta
            try:
                feature = FeatureMeta.objects.get(hash=feature_hash)
            except FeatureMeta.DoesNotExist:
                logger.warning(f"Feature not found: {feature_hash}")
        
        # PrÃ©paration des mÃ©tadonnÃ©es
        meta_data = meta or {}
        meta_data.update({
            'schema_version': '1.0',  # Versioning du format
            'compression': 'zstd',
            'serialization': 'cloudpickle',
        })
        
        # CrÃ©ation en BDD (transaction atomique)
        with transaction.atomic():
            artefact = ArtefactMeta.objects.create(
                hash=hash_value,
                feature=feature,
                size=size_compressed,
                size_uncompressed=size_raw,
                storage_path=relative_path,
                meta=meta_data,
            )
            
            logger.info(
                f"âœ… Artefact created: {hash_value[:8]} "
                f"({size_compressed} bytes, ratio: {size_compressed/size_raw:.2%})"
            )
        
        return artefact
    
    def get_artefact(self, hash_value: str) -> Optional[ArtefactMeta]:
        """
        RÃ©cupÃ¨re les mÃ©tadonnÃ©es d'un artefact.
        
        Args:
            hash_value: Hash SHA-256
        
        Returns:
            Instance ArtefactMeta ou None
        """
        try:
            artefact = ArtefactMeta.objects.get(hash=hash_value)
            artefact.save(update_fields=['last_accessed_at'])  # MAJ last_accessed
            return artefact
        except ArtefactMeta.DoesNotExist:
            return None
    
    def load_artefact(
        self,
        hash_value: str,
        log_access: bool = True,
        user=None
    ) -> object:
        """
        Charge et dÃ©sÃ©rialise un artefact.
        
        Args:
            hash_value: Hash SHA-256
            log_access: Si True, enregistre l'accÃ¨s dans ArtefactAccessLog
            user: Utilisateur effectuant l'accÃ¨s (optionnel)
        
        Returns:
            Objet Python dÃ©sÃ©rialisÃ©
        
        Raises:
            ArtefactMeta.DoesNotExist: Si artefact inexistant
            FileNotFoundError: Si fichier FS manquant
        """
        # VÃ©rification en BDD
        artefact = ArtefactMeta.objects.get(hash=hash_value)
        
        # Chargement depuis FS
        obj = self.storage.load(hash_value)
        
        # MAJ last_accessed
        artefact.save(update_fields=['last_accessed_at'])
        
        # Log d'accÃ¨s (optionnel)
        if log_access:
            ArtefactAccessLog.objects.create(
                artefact=artefact,
                accessed_by=user,
                access_type='download'
            )
        
        logger.debug(f"âœ… Artefact loaded: {hash_value[:8]}")
        
        return obj
    
    def stream_artefact(
        self,
        hash_value: str,
        log_access: bool = True,
        user=None
    ) -> BinaryIO:
        """
        Ouvre un artefact en mode streaming.
        
        Args:
            hash_value: Hash SHA-256
            log_access: Si True, enregistre l'accÃ¨s
            user: Utilisateur effectuant l'accÃ¨s
        
        Returns:
            File object binaire
        
        Raises:
            ArtefactMeta.DoesNotExist: Si artefact inexistant
        """
        # VÃ©rification en BDD
        artefact = ArtefactMeta.objects.get(hash=hash_value)
        
        # MAJ last_accessed
        artefact.save(update_fields=['last_accessed_at'])
        
        # Log d'accÃ¨s
        if log_access:
            ArtefactAccessLog.objects.create(
                artefact=artefact,
                accessed_by=user,
                access_type='stream'
            )
        
        # Ouverture du stream
        return self.storage.stream(hash_value)
    
    def delete_artefact(self, hash_value: str, force: bool = False) -> bool:
        """
        Supprime un artefact.
        
        Args:
            hash_value: Hash SHA-256
            force: Si True, ignore le ref_count (danger !)
        
        Returns:
            True si supprimÃ©, False si impossible
        
        Raises:
            ValueError: Si ref_count > 0 et force=False
        """
        try:
            artefact = ArtefactMeta.objects.get(hash=hash_value)
        except ArtefactMeta.DoesNotExist:
            logger.warning(f"Artefact not found for deletion: {hash_value}")
            return False
        
        # VÃ©rification des rÃ©fÃ©rences
        if not force and not artefact.can_delete():
            raise ValueError(
                f"Cannot delete artefact {hash_value}: "
                f"ref_count={artefact.ref_count} (use force=True to override)"
            )
        
        # Suppression FS
        self.storage.delete(hash_value)
        
        # Suppression BDD
        artefact.delete()
        
        logger.info(f"ðŸ—‘ï¸  Artefact deleted: {hash_value[:8]}")
        
        return True
    
    def cleanup_orphans(self) -> Tuple[int, int]:
        """
        Nettoie les artefacts orphelins (FS sans BDD et BDD sans FS).
        
        Returns:
            Tuple (fs_orphans, db_orphans)
        """
        # RÃ©cupÃ©ration de tous les hash en BDD
        db_hashes = set(
            ArtefactMeta.objects.values_list('hash', flat=True)
        )
        
        # Nettoyage des fichiers orphelins (FS sans BDD)
        fs_orphans = self.storage.cleanup_orphans(db_hashes)
        
        # Nettoyage des entrÃ©es BDD sans fichier
        db_orphans = 0
        for artefact in ArtefactMeta.objects.all():
            if not self.storage.exists(artefact.hash):
                logger.warning(
                    f"BDD entry without file: {artefact.hash[:8]}, deleting..."
                )
                artefact.delete()
                db_orphans += 1
        
        logger.info(
            f"ðŸ§¹ Cleanup completed: {fs_orphans} FS orphans, {db_orphans} DB orphans"
        )
        
        return fs_orphans, db_orphans
    
    def cleanup_old_artefacts(self, days: int = 30) -> int:
        """
        Supprime les artefacts non rÃ©fÃ©rencÃ©s et anciens.
        
        Args:
            days: Ã‚ge minimum en jours
        
        Returns:
            Nombre d'artefacts supprimÃ©s
        """
        from django.utils import timezone
        from datetime import timedelta
        
        cutoff_date = timezone.now() - timedelta(days=days)
        
        old_artefacts = ArtefactMeta.objects.filter(
            ref_count=0,
            last_accessed_at__lt=cutoff_date
        )
        
        deleted_count = 0
        for artefact in old_artefacts:
            try:
                self.delete_artefact(artefact.hash)
                deleted_count += 1
            except Exception as e:
                logger.error(f"Failed to delete old artefact {artefact.hash}: {e}")
        
        logger.info(f"ðŸ§¹ Deleted {deleted_count} old artefacts (>{days} days)")
        
        return deleted_count
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Retourne des statistiques sur les artefacts.
        
        Returns:
            Dictionnaire de statistiques
        """
        from django.db.models import Sum, Avg, Count
        
        stats = ArtefactMeta.objects.aggregate(
            total_count=Count('id'),
            total_size=Sum('size'),
            total_size_uncompressed=Sum('size_uncompressed'),
            avg_compression_ratio=Avg('size') / Avg('size_uncompressed'),
        )
        
        stats['orphans'] = ArtefactMeta.objects.filter(ref_count=0).count()
        stats['referenced'] = ArtefactMeta.objects.filter(ref_count__gt=0).count()
        
        return stats


# Instance globale
artefact_service = ArtefactService()